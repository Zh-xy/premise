{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use examples of [premise](https://github.com/romainsacchi/premise)\n",
    "\n",
    "Author: [romainsacchi](https://github.com/romainsacchi)\n",
    "\n",
    "This notebook shows examples on how to use `premise` to adapt the life cycle inventory database [ecoinvent](https://www.ecoinvent.org/) for prospective environmental impact assessment.\n",
    "\n",
    "This library extract useful information from IAM model output files (such as those of REMIND or IMAGE) and aligns inventories in the ecoinvent database accordingly.\n",
    "\n",
    "With version 1.5.0, the following transformation are available:\n",
    "\n",
    "* `update_electricity()`: create regional electricity markets and adjust efficiency of power plants, including that of photovoltaic panels\n",
    "* `update_cement()`: creates regional markets for clinker production and adjust clinker production efficiency\n",
    "* `update_steel()`: creates regional markets for steel and adjust steel production efficiency and the supply of secondary steel\n",
    "* `update_dac()`: creates region- and scenario-specific inventories for Direct Air Capture (DAC) and Carbon Storage (DACCS) systems.\n",
    "* `update_fuels()`: creates regional markets for liquid and gaseous fuels\n",
    "* `update_emissions`: adjust emission of pollutants (PM, NOx, VOCs) for various activities, based on GAINS model projections.\n",
    "* `update_two_wheelers()`: imports two-wheelers (bicycles, motorbikes, etc.)\n",
    "* `update_cars()`: produces fleet average cars and relinks to activities consuming pasenger car transport\n",
    "* `update_trucks()`: produces fleet average trucks and relinks to activities consuming lorry trnasport\n",
    "* `update_buses()`: imports buses (urban and coach buses, single-deckers and double-deckers)\n",
    "\n",
    "Alternatively, `update_all()` performs all the above-mentioned transformations (with the exception of `update_two_wheelers()`, `update_cars()` and `update_buses()`).\n",
    "\n",
    "There is also the possibility to integrate user-defined scenarios,\n",
    "for which we have a separate notebook.\n",
    "\n",
    "Additional documentation on the methodology is available [here](https://premise.readthedocs.io/en/latest/introduction.html).\n",
    "\n",
    "There's also a **publication** about `premise` [here](https://www.sciencedirect.com/science/article/pii/S136403212200226X?via%3Dihub).\n",
    "\n",
    "## Requirements\n",
    "\n",
    "* **Pyhton 3.9 is highly recommended**\n",
    "* a user license for ecoinvent v.3\n",
    "* a **decryption key**, to be asked from [Romain Sacchi](mailto:romain.sacchi@psi.ch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use case with [brightway2](https://brightway.dev/)\n",
    "\n",
    "`brightway2` is an open source LCA framework for Python.\n",
    "To use `premise` from `brightway2`, it requires that you have an activated `brightway2` project with a `biosphere3` database as well as an ecoinvent v.3 cut-off or consequential database registered in that project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from premise import *\n",
    "import bw2data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### List of available scenarios\n",
    "\n",
    "Some scenarios come installed with the library.\n",
    "They are stored in `data/iam_ouput_files` from the root directory.\n",
    "They are all within the same Shared Socio-Economic Pathway (SSP): SSP2 (nicknamed \"middle of the road\"), which describes a future world (in terms of GDP and demographics development, education, intergovernmental collaboration) very much in line with what has been observed historically..\n",
    "\n",
    "But they are proposed in combination with different climate mitigation targets, called Representative Concentration Pathways (RCP).\n",
    "Read more about SSPs and RCPs, [here](https://www.carbonbrief.org/explainer-how-shared-socioeconomic-pathways-explore-future-climate-change).\n",
    "\n",
    "With REMIND, we have the following SSP/RCP scenarios:\n",
    "* \"SSP1-Base\"\n",
    "* \"SSP5-Base\"\n",
    "* \"SSP2-Base\"\n",
    "* \"SSP2-NPi\"\n",
    "* \"SSP2-NDC\"\n",
    "* \"SSP2-PkBudg1150\"\n",
    "* \"SSP2-PkBudg500\"\n",
    "\n",
    "With IMAGE, we have the following SSP/RCP scenarios:\n",
    "* \"SSP2-Base\"\n",
    "* \"SSP2-RCP26\"\n",
    "* \"SSP2-RCP19\"\n",
    "\n",
    "Refer to [the documentation](https://premise.readthedocs.io/en/latest/extract.html#current-iam-scenarios) for the meaning of thses scenarios.\n",
    "Additionally, [this blog](https://www.carbonbrief.org/explainer-how-shared-socioeconomic-pathways-explore-future-climate-change/) is a good reading material to understand SSPs and RCPs.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Database creation from default scenarios\n",
    "\n",
    "To create a scenario using REMIND's SSP2 Base pathway, from ecoinvent 3.5 for the year 2028, one would execute the following cell. This leads to the extraction of the database, some cleanup as well as importing a few additional inventories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Databases dictionary with 25 objects, including:\n",
       "\tbiosphere3\n",
       "\tcutoff371\n",
       "\tecoinvent 3.8 cutoff\n",
       "\tecoinvent_image_SSP2-Base_2010\n",
       "\tecoinvent_image_SSP2-Base_2020\n",
       "\tecoinvent_image_SSP2-Base_2030\n",
       "\tecoinvent_image_SSP2-Base_2040\n",
       "\tecoinvent_image_SSP2-Base_2050\n",
       "\tecoinvent_image_SSP2-RCP19_2030\n",
       "\tecoinvent_image_SSP2-RCP19_2040\n",
       "Use `list(this object)` to get the complete list."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bw2data.projects.set_current(\"premise\")\n",
    "bw2data.databases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first time you create a premise database, *premise* will store a copy of the ecoinvent database and external inventories, to be able to skip that time-consuming step next time. If you wish to clear this cache (which is only encourage if updating premise or if encountering issues with inventories), do:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cache folder cleared!\n"
     ]
    }
   ],
   "source": [
    "clear_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "premise v.(1, 2, 5)\n",
      "+------------------------------------------------------------------+\n",
      "| Warning                                                          |\n",
      "+------------------------------------------------------------------+\n",
      "| Because some of the scenarios can yield LCI databases            |\n",
      "| containing net negative emission technologies (NET),             |\n",
      "| it is advised to account for biogenic CO2 flows when calculating |\n",
      "| Global Warming potential indicators.                             |\n",
      "| `premise_gwp` provides characterization factors for such flows.  |\n",
      "| It also provides factors for hydrogen emissions to air.          |\n",
      "|                                                                  |\n",
      "| Within your bw2 project:                                         |\n",
      "| from premise_gwp import add_premise_gwp                          |\n",
      "| add_premise_gwp()                                                |\n",
      "+------------------------------------------------------------------+\n",
      "+--------------------------------+----------------------------------+\n",
      "| Utils functions                | Description                      |\n",
      "+--------------------------------+----------------------------------+\n",
      "| clear_cache()                  | Clears the cache folder. Useful  |\n",
      "|                                | when updating `premise`or        |\n",
      "|                                | encountering issues with         |\n",
      "|                                | inventories.                     |\n",
      "+--------------------------------+----------------------------------+\n",
      "| get_regions_definition(model)  | Retrieves the list of countries  |\n",
      "|                                | for each region of the model.    |\n",
      "+--------------------------------+----------------------------------+\n",
      "| ndb.NewDatabase(...)           | Generates a summary of the most  |\n",
      "| ndb.generate_scenario_report() | important scenarios' variables.  |\n",
      "+--------------------------------+----------------------------------+\n",
      "Hide these messages?\n",
      "NewDatabase(..., quiet=True)\n",
      "\n",
      "//////////////////// EXTRACTING SOURCE DATABASE ////////////////////\n",
      "Done!\n",
      "\n",
      "////////////////// IMPORTING DEFAULT INVENTORIES ///////////////////\n",
      "Done!\n",
      "\n",
      "/////////////////////// EXTRACTING IAM DATA ////////////////////////\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "ndb = NewDatabase(\n",
    "    scenarios=[\n",
    "        {\"model\":\"image\", \"pathway\":\"SSP2-RCP19\", \"year\":2050},\n",
    "        {\"model\":\"remind\", \"pathway\":\"SSP2-PkBudg500\", \"year\":2050},\n",
    "    ],\n",
    "    source_db=\"ecoinvent 3.8 cutoff\", # <-- name of the database in the BW2 project. Must be a string.\n",
    "    source_version=\"3.8\", # <-- version of ecoinvent. Can be \"3.5\", \"3.6\", \"3.7\" or \"3.8\". Must be a string.\n",
    "    key='xxxxxxxxxxxxxxxxxxxxxxxxx' # <-- decryption key\n",
    "    # to be requested from the library maintainers if you want ot use default scenarios included in `premise`\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you do not want to integrate the IAM projections in the database, but only wish to have the additional inventories, you can stop here and export the database back to Brightway or other destinations, by using the `write_db_to` methods, like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ndb.write_db_to_brightway()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Howver, if you wish first to proceed with the IAM integration, you need to use the `update_` methods, like so for the electricity sector:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ndb.update_electricity()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ndb.write_db_to_brightway()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "or here with ecoinvent 3.7.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ndb = NewDatabase(\n",
    "        scenarios=[\n",
    "                {\"model\":\"remind\", \"pathway\":\"SSP2-Base\", \"year\":2028}\n",
    "            ],\n",
    "        source_db=\"ecoinvent 3.7 cutoff\", # <-- this is NEW.\n",
    "        source_version=\"3.7.1\", # <-- this is NEW\n",
    "        key='xxxxxxxxxxxxxxxxxxxxxxxxx'\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to create multiple databases at once, just populate the `scenarios` list.\n",
    "You will notice the key `exclude` for which we can list the transformations we do not wish to perform.\n",
    "In this case, we do not wish to update the electricity sector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ndb = NewDatabase(\n",
    "            scenarios=[\n",
    "                {\"model\":\"remind\", \"pathway\":\"SSP2-Base\", \"year\":2020, \"exclude\": [\"update_electricity\"]},\n",
    "                {\"model\":\"remind\", \"pathway\":\"SSP2-Base\", \"year\":2030},\n",
    "                {\"model\":\"remind\", \"pathway\":\"SSP2-Base\", \"year\":2040},\n",
    "                {\"model\":\"remind\", \"pathway\":\"SSP2-Base\", \"year\":2050},\n",
    "            ],\n",
    "            source_db=\"ecoinvent 3.7 cutoff\", # <-- name of the database. Must be a string.\n",
    "            source_version=\"3.7.1\", # <-- version of ecoinvent. Can be \"3.5\", \"3.6\", \"3.7\" or \"3.7.1\"\n",
    "            key='xxxxxxxxxxxxxxxxxxxxxxxxx'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ndb.update_all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When the database is loaded and the additional inventories imported, you can apply a transformation function.\n",
    "For example here, we adjust the efficiency of the power plants to the two scenarios we have loaded.\n",
    "We go more in details later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ndb.update_electricity()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or you can proceed instead to doing all the transformations available (minus any transformation you have listed in `exclude`), like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ndb.update_all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And then, we register these two databases back into brightway2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ndb.write_db_to_brightway()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Consequential\n",
    "\n",
    "`premise` can read in the consequential version of ecoinvent (v.3.8 only).\n",
    "Based on the publication of Maes et al. 2023 (in review), `premise` builds marginal market mixes for electricity and fuels.\n",
    "The identification of marginal suppliers can be influenced by passing a series of arguments to `NewDatabase()`.\n",
    "Additionally, `premise` removes secondary steel technologies from steel markets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from premise import *\n",
    "from datapackage import Package\n",
    "import brightway2 as bw\n",
    "bw.projects.set_current(\"new4\")\n",
    "\n",
    "args = {\"range time\":2, \"duration\":False, \"foresight\":False, \"lead time\":True, \"capital replacement rate\":False, \"measurement\": 0, \"weighted slope start\": 0.75, \"weighted slope end\": 1.00}\n",
    "\n",
    "ndb = NewDatabase(\n",
    "            scenarios=[\n",
    "                {\"model\":\"remind\", \"pathway\":\"SSP2-Base\", \"year\":2020},\n",
    "                {\"model\":\"remind\", \"pathway\":\"SSP2-Base\", \"year\":2030},\n",
    "                {\"model\":\"remind\", \"pathway\":\"SSP2-Base\", \"year\":2040},\n",
    "                {\"model\":\"remind\", \"pathway\":\"SSP2-Base\", \"year\":2050},\n",
    "            ],\n",
    "            source_db=\"ecoinvent 3.8 consequential\", # <-- Must point to the consequential database.\n",
    "            source_version=\"3.8\", # <-- Can only be 3.8.\n",
    "            key='xxxxxxxxxxxxxxxxxxxxxxxxx',\n",
    "            system_model=\"consequential\", # <-- Must specify \"consequential\"\n",
    "            system_model_args=args # Optional. Arguments.\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Database creation from non-default scenarios\n",
    "\n",
    "If you have some specific IAM scenarios (one that is not included in `premise`) you would like to build a database from, you can specify the directory to those.\n",
    "\n",
    "**Important remark**: your scenario file must begin with \"remind_\" or \"image_\". When using a non-default scenario that you provide yourself, you do not have to provide a decryption key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from premise import *\n",
    "import bw2data\n",
    "\n",
    "bw2data.projects.set_current(\"new\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "premise v.(1, 5, 0, 'alpha', 8)\n",
      "+------------------------------------------------------------------+\n",
      "| Warning                                                          |\n",
      "+------------------------------------------------------------------+\n",
      "| Because some of the scenarios can yield LCI databases            |\n",
      "| containing net negative emission technologies (NET),             |\n",
      "| it is advised to account for biogenic CO2 flows when calculating |\n",
      "| Global Warming potential indicators.                             |\n",
      "| `premise_gwp` provides characterization factors for such flows.  |\n",
      "| It also provides factors for hydrogen emissions to air.          |\n",
      "|                                                                  |\n",
      "| Within your bw2 project:                                         |\n",
      "| from premise_gwp import add_premise_gwp                          |\n",
      "| add_premise_gwp()                                                |\n",
      "+------------------------------------------------------------------+\n",
      "+--------------------------------+----------------------------------+\n",
      "| Utils functions                | Description                      |\n",
      "+--------------------------------+----------------------------------+\n",
      "| clear_cache()                  | Clears the cache folder. Useful  |\n",
      "|                                | when updating `premise`or        |\n",
      "|                                | encountering issues with         |\n",
      "|                                | inventories.                     |\n",
      "+--------------------------------+----------------------------------+\n",
      "| get_regions_definition(model)  | Retrieves the list of countries  |\n",
      "|                                | for each region of the model.    |\n",
      "+--------------------------------+----------------------------------+\n",
      "| ndb.NewDatabase(...)           | Generates a summary of the most  |\n",
      "| ndb.generate_scenario_report() | important scenarios' variables.  |\n",
      "+--------------------------------+----------------------------------+\n",
      "Keep uncertainty data?\n",
      "NewDatabase(..., keep_uncertainty_data=True)\n",
      "\n",
      "Hide these messages?\n",
      "NewDatabase(..., quiet=True)\n",
      "\n",
      "//////////////////// EXTRACTING SOURCE DATABASE ////////////////////\n",
      "Done!\n",
      "\n",
      "////////////////// IMPORTING DEFAULT INVENTORIES ///////////////////\n",
      "Done!\n",
      "\n",
      "/////////////////////// EXTRACTING IAM DATA ////////////////////////\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'cement'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Input \u001b[0;32mIn [2]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m ndb \u001b[38;5;241m=\u001b[39m \u001b[43mNewDatabase\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mscenarios\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodel\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mnewiam\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpathway\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpath1-Base\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43myear\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m2028\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m                  \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfilepath\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/Users/romain/Documents\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m        \u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43msource_db\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mecoinvent 3.8 cutoff\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m# <-- name of the database\u001b[39;49;00m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43msource_version\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m3.8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m# <-- version of ecoinvent\u001b[39;49;00m\n\u001b[1;32m      6\u001b[0m \u001b[43m \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/GitHub/premise/premise/ecoinvent_modification.py:519\u001b[0m, in \u001b[0;36mNewDatabase.__init__\u001b[0;34m(self, scenarios, source_version, source_type, key, source_db, source_file_path, additional_inventories, system_model, system_args, use_cached_inventories, use_cached_database, external_scenarios, quiet, keep_uncertainty_data, gains_scenario)\u001b[0m\n\u001b[1;32m    516\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m/////////////////////// EXTRACTING IAM DATA ////////////////////////\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    518\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m scenario \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscenarios:\n\u001b[0;32m--> 519\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[43mIAMDataCollection\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    520\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mscenario\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodel\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    521\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpathway\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mscenario\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpathway\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    522\u001b[0m \u001b[43m        \u001b[49m\u001b[43myear\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mscenario\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43myear\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    523\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexternal_scenarios\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mscenario\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mexternal scenarios\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    524\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfilepath_iam_files\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mscenario\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfilepath\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    525\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkey\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    526\u001b[0m \u001b[43m        \u001b[49m\u001b[43msystem_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msystem_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    527\u001b[0m \u001b[43m        \u001b[49m\u001b[43msystem_model_args\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msystem_model_args\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    528\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgains_scenario\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgains_scenario\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    529\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    530\u001b[0m     scenario[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124miam data\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m data\n\u001b[1;32m    532\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdatapackages:\n",
      "File \u001b[0;32m~/GitHub/premise/premise/data_collection.py:357\u001b[0m, in \u001b[0;36mIAMDataCollection.__init__\u001b[0;34m(self, model, pathway, year, filepath_iam_files, key, external_scenarios, system_model, system_model_args, gains_scenario)\u001b[0m\n\u001b[1;32m    354\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mother_vars \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__get_other_iam_vars(data\u001b[38;5;241m=\u001b[39mdata)\n\u001b[1;32m    356\u001b[0m electricity_efficiencies \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__get_iam_electricity_efficiencies(data\u001b[38;5;241m=\u001b[39mdata)\n\u001b[0;32m--> 357\u001b[0m cement_efficiencies \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__get_iam_cement_efficiencies\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    358\u001b[0m steel_efficiencies \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__get_iam_steel_efficiencies(data\u001b[38;5;241m=\u001b[39mdata)\n\u001b[1;32m    359\u001b[0m fuel_efficiencies \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__get_iam_fuel_efficiencies(data\u001b[38;5;241m=\u001b[39mdata)\n",
      "File \u001b[0;32m~/GitHub/premise/premise/data_collection.py:716\u001b[0m, in \u001b[0;36mIAMDataCollection.__get_iam_cement_efficiencies\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    708\u001b[0m prod \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__get_iam_variable_labels(\n\u001b[1;32m    709\u001b[0m     IAM_CEMENT_VARS, variable\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124miam_aliases\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    710\u001b[0m )\n\u001b[1;32m    711\u001b[0m energy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__get_iam_variable_labels(\n\u001b[1;32m    712\u001b[0m     IAM_CEMENT_VARS, variable\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124menergy_use_aliases\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    713\u001b[0m )\n\u001b[1;32m    715\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m--> 716\u001b[0m     \u001b[38;5;28mall\u001b[39m(v \u001b[38;5;129;01min\u001b[39;00m data\u001b[38;5;241m.\u001b[39mvariables\u001b[38;5;241m.\u001b[39mvalues \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m \u001b[43menergy\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcement\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m)\n\u001b[1;32m    717\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m prod[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcement\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;129;01min\u001b[39;00m data\u001b[38;5;241m.\u001b[39mvariables\u001b[38;5;241m.\u001b[39mvalues\n\u001b[1;32m    718\u001b[0m ):\n\u001b[1;32m    719\u001b[0m     data_to_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;241m/\u001b[39m (\n\u001b[1;32m    720\u001b[0m         data\u001b[38;5;241m.\u001b[39mloc[:, energy[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcement\u001b[39m\u001b[38;5;124m\"\u001b[39m], :]\u001b[38;5;241m.\u001b[39msum(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvariables\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    721\u001b[0m         \u001b[38;5;241m/\u001b[39m data\u001b[38;5;241m.\u001b[39mloc[:, [prod[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcement\u001b[39m\u001b[38;5;124m\"\u001b[39m]], :]\n\u001b[1;32m    722\u001b[0m     )\n\u001b[1;32m    723\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mKeyError\u001b[0m: 'cement'"
     ]
    }
   ],
   "source": [
    "ndb = NewDatabase(\n",
    "    scenarios = [{\"model\":\"newiam\", \"pathway\":\"path1-Base\", \"year\":2028,\n",
    "                  \"filepath\":\"/Users/romain/Documents\"}],        \n",
    "    source_db=\"ecoinvent 3.8 cutoff\", # <-- name of the database\n",
    "    source_version=\"3.8\", # <-- version of ecoinvent\n",
    " )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding inventories\n",
    "Upon the database extraction, you can import some of your Brightway2-compatible inventories like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ndb = NewDatabase(\n",
    "            scenarios=[\n",
    "                {\"model\":\"remind\", \"pathway\":\"SSP2-Base\", \"year\":2030},\n",
    "            ],\n",
    "            source_db=\"ecoinvent 3.7 cutoff\", \n",
    "            source_version=\"3.7.1\",\n",
    "            key='xxxxxxxxxxxxxxxxxxxxxxxxx'\n",
    "            additional_inventories= [ # <-- this is NEW\n",
    "                {\"filepath\": r\"filepath\\to\\excel_file.xlsx\", \"ecoinvent version\": \"3.7\"}, # <-- this is NEW\n",
    "                {\"filepath\": r\"filepath\\to\\another_excel_file.xlsx\", \"ecoinvent version\": \"3.7\"}, # <-- this is NEW\n",
    "            ] # <-- this is NEW\n",
    "                 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use case with ecospold2\n",
    "\n",
    "The source database does not have to be from a brightway2 project.\n",
    "It can be directly extracted from the bunch of ecospold2 files one gets when downloaded from the [ecoinvent website](https://ecoinvent.org).\n",
    "\n",
    "For this, one needs to specify the argument `source_db = \"ecospold\"` as well as `source_file_path`, which is the directory leading to the ecospold files.\n",
    "\n",
    "For example, here we combine the use of a specific (non-default) IAM scenario file with the use of ecospold2 files as data source (ecoinvent 3.5 in this case)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ndb = NewDatabase(\n",
    "        scenarios = [\n",
    "            {\"model\":\"remind\", \"pathway\":\"my_special_scenario\", \"year\":2028,\n",
    "             \"filepath\":r\"C:\\filepath\\to\\your\\scenario\\folder\"}\n",
    "        ],        \n",
    "        source_type=\"ecospold\", # <--- this is NEW\n",
    "        source_file_path=r\"C:\\filepath\\to\\your\\ecosposld\\folder\\datasets\", # <-- this is NEW\n",
    "        source_version=\"3.5\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transformation functions\n",
    "\n",
    "These functions modify the extracted database:\n",
    "\n",
    "* **update_electricity()**: alignment of regional electricity production mixes as well as efficiencies for a number of electricity production technologies, including Carbon Capture and Storage technologies and photovoltaic panels. Also updated the natural gas extraction datasets.\n",
    "\n",
    "* **update_cement()**: adjustment of technologies for cement production (dry, semi-dry, wet, with pre-heater or not), fuel efficiency of kilns, fuel mix of kilns (including biomass and waste fuels) and clinker-to-cement ratio.\n",
    "\n",
    "* **update_steel()**: adjustment of process efficiency, fuel mix and share of secondary steel in steel markets.\n",
    "\n",
    "* **update_dac()**: creates region- and scenario-specific inventories for DAC and DACCS systems. Applies a learning rate on energy and infrastructure needs if the IAM provides the variable.\n",
    "\n",
    "* **update_fuels()**: creates regional markets for liquid and gaseous fuels and relinks fuel-conusming activities to them.\n",
    "\n",
    "* **update_emissions()**: adjusts emission of local air pollutants according to GAINS projections.\n",
    "\n",
    "* **update_cars()**: creates updated inventories for fleet average passenger cars and links back to activities that consume transport.\n",
    "\n",
    "* **update_trucks()**: creates updated inventories for fleet average lorry trucks and links back to activities that consume transport.\n",
    "\n",
    "* **update_two_wheelers()**: create inventories for two-wheelers.\n",
    "\n",
    "* **update_buses()**: create inventories for buses.\n",
    "\n",
    "A look at the documentation is advised.\n",
    "\n",
    "\n",
    "These functions can be applied *separately*, *consecutively* or *altogether* (using instead **.update_all()**).\n",
    "\n",
    "They will apply to all the scenario-specific databases listed in `scenarios`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ndb.update_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from premise import *\n",
    "import bw2data\n",
    "bw2data.projects.set_current(\"some project\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ndb = NewDatabase(\n",
    "            scenarios=[\n",
    "                {'model':'remind','pathway':'SSP2-Base','year':'2020'},\n",
    "                {\"model\":\"image\", \"pathway\":\"SSP2-Base\", \"year\":2034},\n",
    "            ],\n",
    "            key='xxxxxxxxxxxxxxxxxxxxxxxxx',\n",
    "            source_db=\"ecoinvent 3.7 cutoff\",\n",
    "            source_version=\"3.7\", \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ndb.update_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ndb.write_db_to_brightway()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also give your datababases a custom name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ndb.write_db_to_brightway(name=[\"my_custom_name_1\", \"my_custom_name_2\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exclude specific functions\n",
    "Finally, we can exclude some transformation functions when executing `update_all()` like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ndb = NewDatabase(\n",
    "            scenarios=[\n",
    "                {\"model\":\"remind\", \"pathway\":\"SSP2-Base\", \"year\":2030,\n",
    "                 \"exclude\": [\"update_steel\"], # <-- do not execute update_seel()\n",
    "                 \"passenger cars\": {\"regions\":[\"EUR\"]},\"trucks\": {\"regions\":[\"EUR\"]}\n",
    "                },\n",
    "                {\"model\":\"remind\", \"pathway\":\"SSP2-Base\", \"year\":2030,},\n",
    "            ],\n",
    "            key='xxxxxxxxxxxxxxxxxxxxxxxxx',\n",
    "            source_db=\"ecoinvent 3.7 cutoff\",\n",
    "            source_version=\"3.7\", \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### As a Brightway2 database"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Export the modified database to brightway2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ndb.write_db_to_brightway()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### As a sparse matrix representation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or export it as a sparse matrix representation.\n",
    "\n",
    "This will export four files:\n",
    "\n",
    "* \"A_matrix.csv\": matrix coordinates and values of shape (index of activity; index of product; value) for the technosphere\n",
    "* \"A_matrix_index.csv\": labels for indices for A matrix of shape (name of activity, reference product, unit, location, index)\n",
    "* \"B_matrix.csv\": matrix coordinates and values of shape (index of activity; index of biosphere flow; value) for the biosphere\n",
    "* \"B_matrix_index.csv\": labels for indices for B matrix of shape (name of biosphere flow, main compartment, sub-compartmnet, unit, index)\n",
    "\n",
    "As a convenience, you can specifiy a directory where to store the exported matrices.\n",
    "If the directory does not exist, it will be created.\n",
    "If you leave it unspecified, they will be stored in **data/matrices** in the root folder of the library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ndb.write_db_to_matrices(filepath=r\"C:/Users/sacchi_r/Downloads/exported_matrices\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is an example on how to claculate GWP scores using the set of sparse matrices\n",
    "export by `premise`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import sparse\n",
    "#from pypardiso import spsolve <-- use pypardiso if you use an Intel chip, it's much faster!\n",
    "from scipy.sparse.linalg import spsolve\n",
    "from pathlib import Path\n",
    "from csv import reader\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the directory to the set of files produced by premise\n",
    "DIR = Path(r\"/Users/romain/GitHub/premise/premise/data/export/remind/SSP2-PkBudg1150/2040\") \n",
    "\n",
    "# creates dict of activities <--> indices in A matrix\n",
    "A_inds = dict()\n",
    "with open(DIR / \"A_matrix_index.csv\", 'r') as read_obj:\n",
    "    csv_reader = reader(read_obj, delimiter=\";\")\n",
    "    for row in csv_reader:\n",
    "        A_inds[(row[0], row[1], row[2], row[3])] = row[4]\n",
    "\n",
    "A_inds_rev = {int(v):k for k, v in A_inds.items()}\n",
    "\n",
    "# creates dict of bio flow <--> indices in B matrix\n",
    "B_inds = dict()\n",
    "with open(DIR / \"B_matrix_index.csv\", 'r') as read_obj:\n",
    "    csv_reader = reader(read_obj, delimiter=\";\")\n",
    "    for row in csv_reader:\n",
    "        B_inds[(row[0], row[1], row[2], row[3])] = row[4]\n",
    "        \n",
    "B_inds_rev = {int(v):k for k, v in B_inds.items()}\n",
    "\n",
    "# create a sparse A matrix\n",
    "A_coords = np.genfromtxt(DIR / \"A_matrix.csv\", delimiter=\";\", skip_header=1)\n",
    "I = A_coords[:, 0].astype(int)\n",
    "J = A_coords[:, 1].astype(int)\n",
    "A = sparse.csr_matrix((A_coords[:,2], (J, I)))\n",
    "\n",
    "# create a sparse B matrix\n",
    "B_coords = np.genfromtxt(DIR / \"B_matrix.csv\", delimiter=\";\", skip_header=1)\n",
    "I = B_coords[:, 0].astype(int)\n",
    "J = B_coords[:, 1].astype(int)\n",
    "B = sparse.csr_matrix((B_coords[:,2] * -1, (I, J)), shape=(A.shape[0], len(B_inds)))\n",
    "\n",
    "# a vector with a few GWP CFs\n",
    "gwp = np.zeros(B.shape[1])\n",
    "gwp[[int(B_inds[x]) for x in B_inds if x[0]==\"Carbon dioxide, non-fossil, resource correction\"]] = -1\n",
    "#gwp[[int(B_inds[x]) for x in B_inds if x[0]==\"Hydrogen\"]] = 5\n",
    "gwp[[int(B_inds[x]) for x in B_inds if x[0]==\"Carbon dioxide, in air\"]] = -1\n",
    "gwp[[int(B_inds[x]) for x in B_inds if x[0]==\"Carbon dioxide, non-fossil\"]] = 1\n",
    "gwp[[int(B_inds[x]) for x in B_inds if x[0]==\"Carbon dioxide, fossil\"]] = 1\n",
    "gwp[[int(B_inds[x]) for x in B_inds if x[0]==\"Carbon dioxide, from soil or biomass stock\"]] = 1\n",
    "gwp[[int(B_inds[x]) for x in B_inds if x[0]==\"Carbon dioxide, to soil or biomass stock\"]] = -1\n",
    "gwp[[int(B_inds[x]) for x in B_inds if x[0]==\"Carbon monoxide, fossil\"]] = 4.06\n",
    "gwp[[int(B_inds[x]) for x in B_inds if x[0]==\"Methane, fossil\"]] = 29.6\n",
    "\n",
    "l_res = []\n",
    "#for v in range(0, A.shape[0]):\n",
    "# let's limit this to the first 3 activities of the matrix\n",
    "for v in range(0, 3):\n",
    "    f = np.float64(np.zeros(A.shape[0]))\n",
    "    f[v] = 1\n",
    "    A_inv = spsolve(A, f) # <-- this is too slow\n",
    "    C = A_inv * B\n",
    "    l_res.append((C * gwp).sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print the results together with the name of the activity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.019095977241478358,\n",
       "  ('electricity, from municipal waste incineration to generic market for electricity, medium voltage',\n",
       "   'electricity, medium voltage',\n",
       "   'kilowatt hour',\n",
       "   'GR')),\n",
       " (1.2731279013056063,\n",
       "  ('potassium hydroxide production',\n",
       "   'potassium hydroxide',\n",
       "   'kilogram',\n",
       "   'RER')),\n",
       " (0.016362218326803624,\n",
       "  ('heat production, hardwood chips from forest, at furnace 5000kW, state-of-the-art 2014',\n",
       "   'heat, district or industrial, other than natural gas',\n",
       "   'megajoule',\n",
       "   'RoW'))]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[(k, v) for k, v in zip(l_res, list(A_inds_rev.values())[:10])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### As a SimaPro CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ndb.write_db_to_simapro(filepath=r\"C:/Users/sacchi_r/Downloads/exported_simapro_file\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### As a Superstructure database\n",
    "A superstructure database is a database that can accomodate several scenarios, as described [here](https://github.com/dgdekoning/brightway-superstructure), to be then used in [Activity-Browser](https://github.com/LCA-ActivityBrowser/activity-browser).\n",
    "This function will export the superstructure database as well as produce a \"scenario difference file\". Hence, even though you create multiple scenarios, **you only need to write to disk one database**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ndb.write_superstructure_db_to_brightway()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ndb.write_superstructure_db_to_brightway(name=\"my_db\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### As a data package\n",
    "Export a data package, which can be shared. Data packages cna be read by [unfold](https://github.com/polca/unfold) and databases can be reproduced on other computers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ndb.write_datapackage()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scenario report\n",
    "\n",
    "You can generate a spreadsheet report showing the main variables of the scenario you have selected to create your databases.\n",
    "The report is saved in your working directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ndb.generate_scenario_report()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Changes report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can generate a spreadsheet report of the changes made to the original database.\n",
    "It gives an overview on:\n",
    "\n",
    "* the datasets created\n",
    "* the datasets modified\n",
    "* some performance indicators\n",
    "* scaling factors used to scale certain exchanges\n",
    "\n",
    "The report is saved in your working directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ndb.generate_change_report()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
